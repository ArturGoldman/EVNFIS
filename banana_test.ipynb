{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dW2kag3lEQcp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XVaDJ_tboZDY"
   },
   "outputs": [],
   "source": [
    "import torch.distributions as D\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-v3nuKmoW8sF"
   },
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXUKD_M0LUUX",
    "outputId": "213a824b-df3c-4abe-ad0f-6f93c8b1d6ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kHKdLiH9L76k"
   },
   "outputs": [],
   "source": [
    "#weight to point can be added\n",
    "\n",
    "def get_all_vects(a, v, i, u):\n",
    "    while v[i] != u:\n",
    "        if i != 0:\n",
    "            get_all_vects(a, v, i-1, u)\n",
    "        else:\n",
    "            a.append(v.copy())\n",
    "        v[i] += 1\n",
    "    v[i] = 0\n",
    "\n",
    "class Gaussian_Grid(nn.Module):\n",
    "    def __init__(self, dimensions, grid_size, variance, weighting = 'uniform', rand_seed = None):\n",
    "        super(Gaussian_Grid, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.variance = variance\n",
    "        self.dimensions = dimensions\n",
    "        self.grid_distr = list()\n",
    "        #uniform distribution on knots\n",
    "        if weighting == 'uniform':\n",
    "            u = 1/(self.grid_size**self.dimensions)\n",
    "            self.grid_distr = [u for i in range(self.grid_size**self.dimensions)]\n",
    "        #random distribution on knots (seed can be specified)\n",
    "        if weighting == 'random':\n",
    "            if rand_seed is not None:\n",
    "                torch.manual_seed(rand_seed)\n",
    "            cur_sum = 0\n",
    "            for i in range(self.grid_size**self.dimensions):\n",
    "                u = D.Uniform(0, 1-cur_sum).sample().item()\n",
    "                self.grid_distr.append(u)\n",
    "                cur_sum += u\n",
    "        m = D.Categorical(torch.tensor(self.grid_distr))\n",
    "\n",
    "        all_vects = list()\n",
    "        get_all_vects(all_vects, [0.0 for i in range(self.dimensions)], self.dimensions-1, grid_size)\n",
    "        comp = D.Independent(D.Normal(\n",
    "             torch.tensor(all_vects), \n",
    "             self.variance*torch.ones(self.grid_size**self.dimensions,self.dimensions)), 1)\n",
    "        self.gmm = D.MixtureSameFamily(m, comp)\n",
    "\n",
    "\n",
    "    def sampler(self, sample_amnt):\n",
    "        return self.gmm.sample((sample_amnt,))\n",
    "\n",
    "    def log_pdf(self, x):\n",
    "        return self.gmm.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GNqPqiUPFEyB"
   },
   "outputs": [],
   "source": [
    "class Simple_Gaussian(nn.Module):\n",
    "    def __init__(self, dimensions, mean = None, variance = None):\n",
    "        super(Simple_Gaussian, self).__init__()\n",
    "        self.mean = None\n",
    "        if mean is None:\n",
    "            self.mean = torch.zeros(dimensions)\n",
    "        else:\n",
    "            self.mean = torch.FloatTensor(mean)\n",
    "        self.variance = None\n",
    "        if variance is None:\n",
    "            self.variance = torch.eye(dimensions)\n",
    "        else:\n",
    "            self.variance = torch.FloatTensor(variance)\n",
    "        self.norml = D.MultivariateNormal(self.mean.to(dev), self.variance.to(dev)) # * torch.eye(dimensions)\n",
    "\n",
    "    def sampler(self, sample_amnt):\n",
    "        return self.norml.sample((sample_amnt,))\n",
    "\n",
    "    def log_pdf(self, x):\n",
    "        return self.norml.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Banana_Gaussian(nn.Module):\n",
    "    def __init__(self, p=100, b=0.1):\n",
    "        super(Banana_Gaussian, self).__init__()\n",
    "        self.mean = torch.FloatTensor([0, 0])\n",
    "        self.variance = torch.FloatTensor([[p, 0], [0, 1]])\n",
    "        self.norml = D.MultivariateNormal(self.mean.to(dev), self.variance.to(dev)) # * torch.eye(dimensions)\n",
    "        self.p = p\n",
    "        self.b = b\n",
    "        self.samps = None\n",
    "\n",
    "    def sampler(self, sample_amnt):\n",
    "        samps = self.norml.sample((sample_amnt,))\n",
    "        samps[:, 1] = samps[:, 1] + self.b*samps[:, 0]**2-self.p*self.b\n",
    "        return samps\n",
    "\n",
    "    def log_pdf(self, x):\n",
    "        y = x.clone().detach()\n",
    "        y[:, 1] = y[:, 1] - self.b*y[:, 0]**2 +self.p*self.b\n",
    "        return self.norml.log_prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AzlUjxeQaBso"
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    #return (x*x*x).sum(dim=1)\n",
    "    return x[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QJtzfDP5dGa0"
   },
   "outputs": [],
   "source": [
    "def sigma(pred, old, f, p, q, log_dets, coef_ll = 1, coef_var = 0):\n",
    "    ans = 0\n",
    "    if coef_ll is not None:\n",
    "        ans += -coef_ll*(q.log_pdf(pred)+log_dets).sum()\n",
    "    if coef_var is not None:\n",
    "        ans += coef_var*((f(old)**2 *torch.exp(p.log_pdf(old)-q.log_pdf(pred)-log_dets)).mean())\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9coI1gc1B7Yo"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dAT_YfSvz2yp"
   },
   "outputs": [],
   "source": [
    "def estimate_params(p, q, f, model, sample_size = 10**3, lear_rt = 1e-3, epoch_amnt = 2*10**3, lr_downing_num=1,\n",
    "                   ll_coef = 1, var_coef=0):\n",
    "    lr = lear_rt #learning rate\n",
    "    max_epochs = epoch_amnt\n",
    "    samples_amnt = sample_size\n",
    "\n",
    "    xb = p.sampler(samples_amnt)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-6)\n",
    "\n",
    "    lambda2 = lambda itnum: 0.9\n",
    "    scheduler = optim.lr_scheduler.MultiplicativeLR(opt, lr_lambda=lambda2)\n",
    "\n",
    "    #best_model = None\n",
    "    #wanted to deepcopy.....\n",
    "    \n",
    "    best_min_loss = float('Inf')\n",
    "\n",
    "    for itnum in range(lr_downing_num):\n",
    "        epoch_cnt = 0\n",
    "        inc_res = 0\n",
    "        cur_res = 10**6\n",
    "        scheduler.step()\n",
    "\n",
    "        # heuristic of stopping\n",
    "        while True:\n",
    "            if max_epochs is not None:\n",
    "                if epoch_cnt > max_epochs:\n",
    "                    break\n",
    "            zb, log_dets = model(xb)\n",
    "            log_dets = log_dets.squeeze()\n",
    "            loss = sigma(zb, xb, f, p, q, log_dets, ll_coef, var_coef)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(\"nan loss\")\n",
    "                break\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            is_nan_param = False\n",
    "            for elem in model.parameters():\n",
    "                if torch.any(torch.isnan(elem)).item():\n",
    "                    print(\"nan param\")\n",
    "                    is_nan_param = True\n",
    "                    break\n",
    "            if is_nan_param:\n",
    "                break\n",
    "\n",
    "            if best_min_loss > loss.item():\n",
    "                inc_res = 0\n",
    "                best_min_loss = loss.item()\n",
    "            \n",
    "            if inc_res > 50:\n",
    "                break\n",
    "\n",
    "            prev_res = cur_res\n",
    "            cur_res = loss\n",
    "            epoch_cnt += 1\n",
    "            inc_res += 1\n",
    "\n",
    "            \"\"\"\n",
    "            if epoch_cnt % 100 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Cur iter:\", itnum)\n",
    "                print(\"Curr_loss:\", loss)\n",
    "                print(\"Min_loss:\", best_min_loss)\n",
    "                print(\"Current epochs:\", epoch_cnt) \n",
    "                print(\"Current tolerance:\", torch.abs(cur_res-prev_res))\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "938rd36OANNc"
   },
   "outputs": [],
   "source": [
    "def new_expectancy(f, p, q, test_amnt, sample_amnt, model):\n",
    "    results = list()\n",
    "    for i in range(test_amnt):\n",
    "        mean = 0\n",
    "        z = q.sampler(sample_amnt)\n",
    "        x, log_det = model(z, mode='inverse')\n",
    "        #plt.scatter(x[:, 0], x[:, 1])\n",
    "        #plt.grid()\n",
    "        #plt.show()\n",
    "        \"\"\"\n",
    "        print(\"z\", z)\n",
    "        print(\"x\", x)\n",
    "        print(\"f(x)\", f(x))\n",
    "        print(\"p.pdf\", p.pdf(x))\n",
    "        print(\"tx\", torch.exp(q_dist.log_pdf(z) - log_det.squeeze()) )\n",
    "        print(\"1/tx\", torch.exp(-q_dist.log_pdf(z) + log_det.squeeze()) )\n",
    "        print(\"p.pdf* 1/tx\", p.pdf(x)*torch.exp(-q_dist.log_pdf(z) + log_det.squeeze()) )\n",
    "        print(f(x)*p.pdf(x)*torch.exp(-q_dist.log_pdf(z) + log_det.squeeze()) )\n",
    "        \"\"\"\n",
    "        mean = (f(x)*torch.exp(p.log_pdf(x)-q_dist.log_pdf(z) + log_det.reshape(1, -1))).mean()\n",
    "        results.append(mean.item())\n",
    "        #if i%10 == 0:\n",
    "        #    print(i)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GvzRZRhWz23C"
   },
   "outputs": [],
   "source": [
    "import myfl as fnn\n",
    "\n",
    "\n",
    "def build_model(data_dimensions, num_hidden, num_blocks, mtype = 'realnvp'):\n",
    "    num_inputs = data_dimensions\n",
    "    num_cond_inputs = None\n",
    "\n",
    "    modules = []\n",
    "\n",
    "    if mtype == \"maf\":\n",
    "        for _ in range(num_blocks):\n",
    "            modules += [\n",
    "                    fnn.MADE(num_inputs, num_hidden, None, act='tanh'),\n",
    "                    fnn.BatchNormFlow(num_inputs),\n",
    "                    fnn.Reverse(num_inputs)\n",
    "                ]\n",
    "    elif mtype == 'realnvp':\n",
    "        mask = torch.arange(0, num_inputs) % 2\n",
    "        for _ in range(num_blocks):\n",
    "            modules += [\n",
    "                fnn.CouplingLayer(\n",
    "                    num_inputs, num_hidden, mask, None,\n",
    "                    s_act='tanh', t_act='relu'),\n",
    "                fnn.BatchNormFlow(num_inputs)\n",
    "            ]\n",
    "            mask = 1 - mask\n",
    "    elif mtype == 'maf-split':\n",
    "        #does not work\n",
    "        for _ in range(num_blocks):\n",
    "            modules += [\n",
    "                fnn.MADESplit(num_inputs, num_hidden, num_cond_inputs,\n",
    "                            s_act='tanh', t_act='relu'),\n",
    "                fnn.BatchNormFlow(num_inputs),\n",
    "                fnn.Reverse(num_inputs)\n",
    "            ]\n",
    "    elif mtype == 'maf-split-glow':\n",
    "        #does not work\n",
    "        for _ in range(num_blocks):\n",
    "            modules += [\n",
    "                fnn.MADESplit(num_inputs, num_hidden, num_cond_inputs,\n",
    "                            s_act='tanh', t_act='relu'),\n",
    "                fnn.BatchNormFlow(num_inputs),\n",
    "                fnn.InvertibleMM(num_inputs)\n",
    "            ]\n",
    "\n",
    "\n",
    "    model = fnn.FlowSequential(*modules)\n",
    "\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.orthogonal_(module.weight)\n",
    "            if hasattr(module, 'bias') and module.bias is not None:\n",
    "                module.bias.data.fill_(0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mlbkXaLfQyJ4"
   },
   "outputs": [],
   "source": [
    "def regular_expectancy(f, p, test_amnt, sample_amnt):\n",
    "    results = list()\n",
    "    for i in range(test_amnt):\n",
    "        samples = p.sampler(sample_amnt)\n",
    "        mean = f(samples).mean()\n",
    "        results.append(mean.item())\n",
    "        #if i%10 == 0:\n",
    "        #    print(i)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hmzr-9--RUlF"
   },
   "outputs": [],
   "source": [
    "def box_comp(a, b):                                                    \n",
    "    data = [a, b]                                             \n",
    "    plt.figure(figsize=(12,8))                 \n",
    "    plt.boxplot(data, showfliers = False, labels =                              \n",
    "                [\"MC Vanila\", \"norm_flow\"])\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joxH5MUiQzfc",
    "outputId": "a14e623a-65e3-446a-fe45-d0f506252866",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 3, 3, 'realnvp', 5000]\n",
      "[0.01, 3, 3, 'realnvp', 20000]\n",
      "[0.01, 3, 3, 'maf', 5000]\n",
      "[0.01, 3, 3, 'maf', 20000]\n",
      "[0.01, 3, 8, 'realnvp', 5000]\n",
      "[0.01, 3, 8, 'realnvp', 20000]\n",
      "[0.01, 3, 8, 'maf', 5000]\n",
      "[0.01, 3, 8, 'maf', 20000]\n",
      "[0.01, 3, 15, 'realnvp', 5000]\n",
      "[0.01, 3, 15, 'realnvp', 20000]\n",
      "[0.01, 3, 15, 'maf', 5000]\n",
      "[0.01, 3, 15, 'maf', 20000]\n",
      "[0.01, 15, 3, 'realnvp', 5000]\n",
      "[0.01, 15, 3, 'realnvp', 20000]\n",
      "[0.01, 15, 3, 'maf', 5000]\n",
      "[0.01, 15, 3, 'maf', 20000]\n",
      "[0.01, 15, 8, 'realnvp', 5000]\n",
      "[0.01, 15, 8, 'realnvp', 20000]\n",
      "[0.01, 15, 8, 'maf', 5000]\n",
      "[0.01, 15, 8, 'maf', 20000]\n",
      "[0.01, 15, 15, 'realnvp', 5000]\n",
      "[0.01, 15, 15, 'realnvp', 20000]\n",
      "[0.01, 15, 15, 'maf', 5000]\n",
      "[0.01, 15, 15, 'maf', 20000]\n",
      "[0.01, 25, 3, 'realnvp', 5000]\n",
      "[0.01, 25, 3, 'realnvp', 20000]\n",
      "[0.01, 25, 3, 'maf', 5000]\n",
      "[0.01, 25, 3, 'maf', 20000]\n",
      "[0.01, 25, 8, 'realnvp', 5000]\n",
      "[0.01, 25, 8, 'realnvp', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.01, 25, 8, 'maf', 5000]\n",
      "[0.01, 25, 8, 'maf', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.01, 25, 15, 'realnvp', 5000]\n",
      "[0.01, 25, 15, 'realnvp', 20000]\n",
      "[0.01, 25, 15, 'maf', 5000]\n",
      "[0.01, 25, 15, 'maf', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.001, 3, 3, 'realnvp', 5000]\n",
      "[0.001, 3, 3, 'realnvp', 20000]\n",
      "[0.001, 3, 3, 'maf', 5000]\n",
      "[0.001, 3, 3, 'maf', 20000]\n",
      "[0.001, 3, 8, 'realnvp', 5000]\n",
      "[0.001, 3, 8, 'realnvp', 20000]\n",
      "[0.001, 3, 8, 'maf', 5000]\n",
      "[0.001, 3, 8, 'maf', 20000]\n",
      "[0.001, 3, 15, 'realnvp', 5000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.001, 3, 15, 'realnvp', 20000]\n",
      "[0.001, 3, 15, 'maf', 5000]\n",
      "[0.001, 3, 15, 'maf', 20000]\n",
      "[0.001, 15, 3, 'realnvp', 5000]\n",
      "[0.001, 15, 3, 'realnvp', 20000]\n",
      "[0.001, 15, 3, 'maf', 5000]\n",
      "[0.001, 15, 3, 'maf', 20000]\n",
      "[0.001, 15, 8, 'realnvp', 5000]\n",
      "[0.001, 15, 8, 'realnvp', 20000]\n",
      "[0.001, 15, 8, 'maf', 5000]\n",
      "[0.001, 15, 8, 'maf', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.001, 15, 15, 'realnvp', 5000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.001, 15, 15, 'realnvp', 20000]\n",
      "[0.001, 15, 15, 'maf', 5000]\n",
      "[0.001, 15, 15, 'maf', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.001, 25, 3, 'realnvp', 5000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.001, 25, 3, 'realnvp', 20000]\n",
      "[0.001, 25, 3, 'maf', 5000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.001, 25, 3, 'maf', 20000]\n",
      "[0.001, 25, 8, 'realnvp', 5000]\n",
      "[0.001, 25, 8, 'realnvp', 20000]\n",
      "[0.001, 25, 8, 'maf', 5000]\n",
      "[0.001, 25, 8, 'maf', 20000]\n",
      "[0.001, 25, 15, 'realnvp', 5000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.001, 25, 15, 'realnvp', 20000]\n",
      "[0.001, 25, 15, 'maf', 5000]\n",
      "[0.001, 25, 15, 'maf', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.0001, 3, 3, 'realnvp', 5000]\n",
      "[0.0001, 3, 3, 'realnvp', 20000]\n",
      "[0.0001, 3, 3, 'maf', 5000]\n",
      "[0.0001, 3, 3, 'maf', 20000]\n",
      "[0.0001, 3, 8, 'realnvp', 5000]\n",
      "[0.0001, 3, 8, 'realnvp', 20000]\n",
      "[0.0001, 3, 8, 'maf', 5000]\n",
      "[0.0001, 3, 8, 'maf', 20000]\n",
      "[0.0001, 3, 15, 'realnvp', 5000]\n",
      "[0.0001, 3, 15, 'realnvp', 20000]\n",
      "[0.0001, 3, 15, 'maf', 5000]\n",
      "[0.0001, 3, 15, 'maf', 20000]\n",
      "[0.0001, 15, 3, 'realnvp', 5000]\n",
      "[0.0001, 15, 3, 'realnvp', 20000]\n",
      "[0.0001, 15, 3, 'maf', 5000]\n",
      "[0.0001, 15, 3, 'maf', 20000]\n",
      "[0.0001, 15, 8, 'realnvp', 5000]\n",
      "[0.0001, 15, 8, 'realnvp', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.0001, 15, 8, 'maf', 5000]\n",
      "[0.0001, 15, 8, 'maf', 20000]\n",
      "[0.0001, 15, 15, 'realnvp', 5000]\n",
      "[0.0001, 15, 15, 'realnvp', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.0001, 15, 15, 'maf', 5000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.0001, 15, 15, 'maf', 20000]\n",
      "[0.0001, 25, 3, 'realnvp', 5000]\n",
      "[0.0001, 25, 3, 'realnvp', 20000]\n",
      "[0.0001, 25, 3, 'maf', 5000]\n",
      "[0.0001, 25, 3, 'maf', 20000]\n",
      "[0.0001, 25, 8, 'realnvp', 5000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.0001, 25, 8, 'realnvp', 20000]\n",
      "[0.0001, 25, 8, 'maf', 5000]\n",
      "nan param\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "nan loss\n",
      "[0.0001, 25, 8, 'maf', 20000]\n",
      "nan param\n",
      "nan loss\n",
      "[0.0001, 25, 15, 'realnvp', 5000]\n",
      "[0.0001, 25, 15, 'realnvp', 20000]\n",
      "[0.0001, 25, 15, 'maf', 5000]\n",
      "[0.0001, 25, 15, 'maf', 20000]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dimensions = 2 # how many dimensions are there in our variable\n",
    "# should work for >= 2\n",
    "lrs = [1e-2, 1e-3, 1e-4]\n",
    "layer_amnt = [3, 15, 25]\n",
    "hidden_size = [3, 8, 15]\n",
    "flow_type = ['realnvp', 'maf']\n",
    "epoch_amnt = [5*10**3, 2*10**4]\n",
    "\n",
    "column_names = [\"learning rate\", \"layer amount\", \n",
    "                \"hidden layer size\", \"flow type\", \"max_amount of epochs\",\n",
    "               \"MC Vanila\", \"norm_flow\"]\n",
    "if os.path.exists('./banana_res.csv.csv'):\n",
    "    output = pd.read_csv('banana_res.csv.csv')\n",
    "else:\n",
    "    output = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for combination in itertools.product(lrs, layer_amnt, hidden_size, flow_type, epoch_amnt):\n",
    "    cur_params = list(combination)\n",
    "    was_comb = False\n",
    "    for i in range(output.shape[0]):\n",
    "        old_params = output.iloc[i, :len(cur_params)]\n",
    "        if old_params.tolist() == cur_params:\n",
    "            was_comb = True\n",
    "            break\n",
    "    if was_comb:\n",
    "        continue\n",
    "    print(cur_params)\n",
    "    clr, clamnt, chidsz, cfltype, cepamnt = combination\n",
    "    model = build_model(data_dimensions, clamnt, chidsz, cfltype)\n",
    "    p = 100\n",
    "    b = 0.01\n",
    "    p_dist = Banana_Gaussian(p, b)\n",
    "    q_dist = Simple_Gaussian(data_dimensions)\n",
    "    estimate_params(p_dist, q_dist, func, model, sample_size = 10**3, lear_rt = clr, \n",
    "                    epoch_amnt = cepamnt, lr_downing_num = 5, ll_coef = None, var_coef=1)\n",
    "    \n",
    "    model.eval()\n",
    "    reg = regular_expectancy(func, p_dist, 100, 10**3)\n",
    "    newe = new_expectancy(func, p_dist, q_dist, 100, 10**3, model)\n",
    "    cur_params.append(reg)\n",
    "    cur_params.append(newe)\n",
    "    cur_params = pd.Series(cur_params, index=output.columns)\n",
    "    output = output.append(cur_params, ignore_index=True)\n",
    "    output.to_csv('banana_res.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3+ dim",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
